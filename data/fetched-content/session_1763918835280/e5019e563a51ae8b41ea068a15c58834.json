{
  "url": "https://www.semanticscholar.org/paper/GPT-4-Technical-Report-Achiam-Adler/163b4d6a79a5b19af88b8585456363340d9efd04",
  "fetchedAt": "2025-11-23T17:27:19.755Z",
  "method": "readability",
  "originalSize": 1061133,
  "extractedSize": 2763,
  "title": "[PDF] GPT-4 Technical Report | Semantic Scholar",
  "content": "GPT-4o System CardComputer Science2024This System Card provides a detailed look at GPT-4o's capabilities, limitations, and safety evaluations across multiple categories, focusing on speech-to-speech while also evaluating text and image capabilities, and measures the authors've implemented to ensure the model is safe and aligned.2,321[PDF]GPT-4 passes the bar examD. KatzM. BommaritoShang GaoPablo ArredondoComputer Science, EducationPhilosophical Transactions of the Royal Society A2024GPT-4 significantly outperforms both human test-takers and prior models, demonstrating a 26% increase over ChatGPT and beating humans in five of seven subject areas, document not just the rapid and remarkable advance of large language model performance generally, but also the potential for such models to support the delivery of legal services in society.496GPT-4V(ision) System CardComputer Science, Engineering2023This system card outlines how OpenAI prepared the vision capabilities of GPT-4 for deployment and describes the early access period of the model for small scale users and safety learnings OpenAI gained from this period, multimodal evaluations built to study the modelâ€™s fitness for deployment, key findings of expert red teamers, and the mitigations OpenAI implemented prior to broad release.387Highly InfluencedAn Evaluation of GPT-4V and Gemini in Online VQAMengchen LiuChongyan ChenComputer Science2023This work evaluates two state-of-the-art LMMs, GPT-4V and Gemini, on a new visual question answering dataset sourced from an authentic online question answering community, and conducts fine-grained analysis by generating seven types of metadata for nearly 2,000 visual questions, such as image type and the required image processing capabilities.8[PDF]Customizing General-Purpose Foundation Models for Medical Report GenerationBang YangAsif RazaYuexian ZouTong ZhangComputer Science, Medicine2023This work proposes customizing off-the-shelf general-purpose large-scale pre-trained models, i.e., foundation models (FMs), in computer vision and natural language processing with a specific focus on medical report generation and demonstrates that unfreezing EVA-ViT-g to learn medical image representations, followed by parameter-efficient training of ChatGLM-6B to capture the writing styles of medical reports, is essential for achieving optimal results.14[PDF]Tele-FLM Technical ReportXiang LiYiqun Yao Tiejun HuangComputer Science, Linguistics2024This report introduces Tele-FLM (aka FLM-2), a 52B open-sourced multilingual large language model that features a stable, efficient pre-training paradigm and enhanced factual judgment capabilities and demonstrates superior multilingual language modeling abilities, measured by BPB on textual corpus.9[PDF]",
  "htmlPath": "data/fetched-content/session_1763918835280/e5019e563a51ae8b41ea068a15c58834.html",
  "confidence": 1
}